{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6ca24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8c462d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Loading images and labels into arrays\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    categories = ['benign', 'malignant']\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for category in categories:\n",
    "        folder_path = os.path.join(dataset_path, category)\n",
    "        class_label = category\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path).resize(img_size).convert('RGB')\n",
    "                data.append(np.array(img))\n",
    "                labels.append(class_label)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Step 3: Categorical Labels\n",
    "# Load data\n",
    "data_path = r\"C:\\Users\\LLR User\\Desktop\\Coding\\code\\skin-cancer\\Dataset\"  # Replace with your actual dataset folder path\n",
    "data, labels = load_images_and_labels(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1824202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be6b951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Normalization\n",
    "data = data / 255.0  # Normalize pixel values\n",
    "\n",
    "# Step 5: Train and Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, stratify=labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35f4e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LLR User\\miniconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Model Building (Basic CNN)\n",
    "def build_cnn_model(input_shape=(224, 224, 3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fb669a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LLR User\\miniconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 772ms/step - accuracy: 0.5250 - loss: 0.7111 - val_accuracy: 0.6128 - val_loss: 0.5948\n",
      "Epoch 2/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 687ms/step - accuracy: 0.6790 - loss: 0.5834 - val_accuracy: 0.7744 - val_loss: 0.5055\n",
      "Epoch 3/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 692ms/step - accuracy: 0.7568 - loss: 0.5223 - val_accuracy: 0.7531 - val_loss: 0.4826\n",
      "Epoch 4/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 704ms/step - accuracy: 0.7443 - loss: 0.5129 - val_accuracy: 0.7762 - val_loss: 0.4672\n",
      "Epoch 5/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 764ms/step - accuracy: 0.7859 - loss: 0.4596 - val_accuracy: 0.7229 - val_loss: 0.5120\n",
      "Epoch 1/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.5358 - loss: 0.7325 - val_accuracy: 0.7367 - val_loss: 0.6210\n",
      "Epoch 2/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 819ms/step - accuracy: 0.6269 - loss: 0.6259 - val_accuracy: 0.6673 - val_loss: 0.5546\n",
      "Epoch 3/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 761ms/step - accuracy: 0.7009 - loss: 0.5362 - val_accuracy: 0.7794 - val_loss: 0.5123\n",
      "Epoch 4/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 729ms/step - accuracy: 0.7344 - loss: 0.5181 - val_accuracy: 0.7900 - val_loss: 0.4482\n",
      "Epoch 5/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 791ms/step - accuracy: 0.7722 - loss: 0.4715 - val_accuracy: 0.7954 - val_loss: 0.4292\n",
      "Epoch 1/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.4961 - loss: 0.8076 - val_accuracy: 0.7260 - val_loss: 0.6603\n",
      "Epoch 2/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 764ms/step - accuracy: 0.6158 - loss: 0.6468 - val_accuracy: 0.7420 - val_loss: 0.5965\n",
      "Epoch 3/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 807ms/step - accuracy: 0.7030 - loss: 0.6036 - val_accuracy: 0.5463 - val_loss: 0.6773\n",
      "Epoch 4/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 874ms/step - accuracy: 0.6385 - loss: 0.6141 - val_accuracy: 0.7544 - val_loss: 0.4848\n",
      "Epoch 5/5\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 847ms/step - accuracy: 0.7683 - loss: 0.5000 - val_accuracy: 0.7865 - val_loss: 0.4522\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Cross-validating model using K-Fold (optional but shown)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "accuracies = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train, np.argmax(y_train, axis=1)):\n",
    "    model = build_cnn_model()\n",
    "    model.fit(X_train[train_idx], y_train[train_idx], epochs=5, verbose=1, validation_data=(X_train[val_idx], y_train[val_idx]))\n",
    "    scores = model.evaluate(X_train[val_idx], y_train[val_idx], verbose=0)\n",
    "    accuracies.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4ffd7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [0.7229129672050476, 0.7953736782073975, 0.7864768505096436]\n",
      "Mean Accuracy: 0.7682544986406962\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Accuracies:\", accuracies)\n",
    "print(\"Mean Accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d49ed9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 711ms/step - accuracy: 0.5792 - loss: 0.6880 - val_accuracy: 0.7633 - val_loss: 0.5480\n",
      "Epoch 2/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 755ms/step - accuracy: 0.7157 - loss: 0.5530 - val_accuracy: 0.7929 - val_loss: 0.4500\n",
      "Epoch 3/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 725ms/step - accuracy: 0.7260 - loss: 0.5196 - val_accuracy: 0.8284 - val_loss: 0.4353\n",
      "Epoch 4/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 688ms/step - accuracy: 0.7712 - loss: 0.4605 - val_accuracy: 0.7929 - val_loss: 0.4466\n",
      "Epoch 5/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 693ms/step - accuracy: 0.7578 - loss: 0.4804 - val_accuracy: 0.8225 - val_loss: 0.4228\n",
      "Epoch 6/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 706ms/step - accuracy: 0.7835 - loss: 0.4638 - val_accuracy: 0.8047 - val_loss: 0.4036\n",
      "Epoch 7/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 701ms/step - accuracy: 0.7726 - loss: 0.4521 - val_accuracy: 0.8047 - val_loss: 0.4109\n",
      "Epoch 8/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 662ms/step - accuracy: 0.7885 - loss: 0.4264 - val_accuracy: 0.8107 - val_loss: 0.4165\n",
      "Epoch 9/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 674ms/step - accuracy: 0.7822 - loss: 0.4081 - val_accuracy: 0.7870 - val_loss: 0.4465\n",
      "Epoch 10/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 652ms/step - accuracy: 0.7882 - loss: 0.4176 - val_accuracy: 0.8166 - val_loss: 0.3985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18ced52d300>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Testing model\n",
    "model = build_cnn_model()\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a7aa552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ce642ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7630331753554502\n",
      "Confusion Matrix:\n",
      " [[173  58]\n",
      " [ 42 149]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78       231\n",
      "           1       0.72      0.78      0.75       191\n",
      "\n",
      "    accuracy                           0.76       422\n",
      "   macro avg       0.76      0.76      0.76       422\n",
      "weighted avg       0.77      0.76      0.76       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy & classification report\n",
    "acc = accuracy_score(y_true, y_pred_classes)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred_classes))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b189c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2109 images.\n",
      "Class Weights: {0: np.float64(0.9158523344191096), 1: np.float64(1.1011749347258486)}\n",
      "---  Training Custom CNN  ---\n",
      "Experiment: cnn_l2_0.0001_drop_0.5_filters_32_dense_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LLR User\\miniconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,437,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m9,437,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,828,290</span> (37.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,828,290\u001b[0m (37.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,827,330</span> (37.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,827,330\u001b[0m (37.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LLR User\\miniconda3\\envs\\tf-env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7209 - loss: 6.0426\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54739, saving model to cnn_cnn_l2_0.0001_drop_0.5_filters_32_dense_256.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4s/step - accuracy: 0.7208 - loss: 6.0331 - val_accuracy: 0.5474 - val_loss: 9.1959 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7363 - loss: 3.1584\n",
      "Epoch 2: val_accuracy did not improve from 0.54739\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 5s/step - accuracy: 0.7364 - loss: 3.1435 - val_accuracy: 0.5474 - val_loss: 25.9322 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7724 - loss: 0.7863\n",
      "Epoch 3: val_accuracy did not improve from 0.54739\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 4s/step - accuracy: 0.7722 - loss: 0.7865 - val_accuracy: 0.5474 - val_loss: 4.2304 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7504 - loss: 0.7168\n",
      "Epoch 4: val_accuracy improved from 0.54739 to 0.72749, saving model to cnn_cnn_l2_0.0001_drop_0.5_filters_32_dense_256.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#   ---  Jupyter Notebook - Advanced Skin Cancer Classification  ---\n",
    "   \n",
    "#   Cell 1: Import Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    accuracy_score,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16,\n",
    "    InceptionV3,\n",
    "    Xception,\n",
    "    NASNetMobile,\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import datetime\n",
    "\n",
    "#   Cell 2: Define Helper Functions\n",
    "\n",
    "def enhance_image(image_array):\n",
    "    \"\"\"Enhances image using CLAHE.\"\"\"\n",
    "    lab = cv2.cvtColor(image_array, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    enhanced = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)\n",
    "    return enhanced\n",
    "\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    \"\"\"Loads and preprocesses images and labels.\"\"\"\n",
    "    categories = ['benign', 'malignant']\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for category in categories:\n",
    "        folder_path = os.path.join(dataset_path, category)\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, img_size)\n",
    "                image = enhance_image(image)\n",
    "                data.append(image)\n",
    "                labels.append(category)\n",
    "            else:\n",
    "                print(f\"Error loading image: {img_path}\")\n",
    "\n",
    "    data = np.array(data, dtype=\"float32\") / 255.0  #   Normalize\n",
    "    labels = np.array(labels)\n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(labels)  #   0 for benign, 1 for malignant\n",
    "    labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "    print(f\"Loaded {len(data)} images.\")\n",
    "    return data, labels\n",
    "\n",
    "def create_cnn_model(\n",
    "    img_height, img_width, num_classes, l2_reg=0.0001, dropout_rate=0.5, filters=[32, 64, 128, 256], dense_units=256\n",
    "):\n",
    "    \"\"\"Creates a customizable CNN model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(\n",
    "            filters[0],\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            input_shape=(img_height, img_width, 3),\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(\n",
    "            filters[1],\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(\n",
    "            filters[2],\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(\n",
    "            filters[3],\n",
    "            (3, 3),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            dense_units,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(\n",
    "            num_classes,\n",
    "            activation='softmax',\n",
    "            kernel_regularizer=l2(l2_reg),\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def create_transfer_learning_model(\n",
    "    base_model, img_height, img_width, num_classes, trainable_layers=-10\n",
    "):\n",
    "    \"\"\"Creates a transfer learning model.\"\"\"\n",
    "    input_layer = Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(input_layer, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    #   Freeze layers\n",
    "    if trainable_layers > 0:\n",
    "        for layer in base_model.layers[:trainable_layers]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers[trainable_layers:]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    use_augmentation=True,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    checkpoint_path=\"skin_cancer_model.h5\",\n",
    "    class_weights=None,  #   For class imbalance\n",
    "    experiment_name=\"experiment\",\n",
    "):\n",
    "    \"\"\"Trains the CNN model.\"\"\"\n",
    "\n",
    "    if use_augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest',\n",
    "        )\n",
    "        datagen.fit(train_data)\n",
    "        train_generator = datagen.flow(\n",
    "            train_data, train_labels, batch_size=batch_size\n",
    "        )\n",
    "        training_data = train_generator\n",
    "    else:\n",
    "        training_data = (train_data, (train_labels))\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "    )\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', factor=0.5, patience=7, verbose=1, min_lr=1e-6\n",
    "    )\n",
    "    log_dir = \"logs/fit/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        training_data,\n",
    "        validation_data=(val_data, val_labels),\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint, early_stopping, lr_scheduler, tensorboard_callback],\n",
    "        verbose=1,\n",
    "        class_weight=class_weights,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, val_data, val_labels, model_name=\"model\"):\n",
    "    \"\"\"Evaluates the trained model.\"\"\"\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    loss, accuracy = model.evaluate(val_data, val_labels, verbose=0)\n",
    "    print(f\"Validation Loss: {loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_true = np.argmax(val_labels, axis=1)\n",
    "    y_pred_prob = model.predict(val_data, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve ({model_name})')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "#   Cell 3: Set Parameters\n",
    "\n",
    "dataset_path = r\"C:\\Users\\LLR User\\Desktop\\Coding\\code\\skin-cancer\\Dataset\"  #   <---  SET THIS!\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "num_classes = 2  #   Binary classification\n",
    "batch_size = 32\n",
    "epochs = 100  #   Increased epochs, EarlyStopping will handle it\n",
    "use_data_augmentation = True  #   <---  SET THIS!\n",
    "\n",
    "#   Hyperparameter Ranges (for basic experimentation)\n",
    "l2_regs = [0.0001, 0.00001]\n",
    "dropout_rates = [0.5, 0.4]\n",
    "filter_sizes = [[32, 64, 128, 256], [64, 128, 256, 512]]\n",
    "dense_units_sizes = [256, 512]\n",
    "\n",
    "#   Cell 4: Load Data\n",
    "\n",
    "data, labels = load_images_and_labels(dataset_path, (img_height, img_width))\n",
    "\n",
    "#   Cell 5: Split Data\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42, stratify=np.argmax(labels, axis=1)\n",
    ")\n",
    "\n",
    "#   Cell 6: Calculate Class Weights (if needed)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "if np.sum(train_labels[:, 0]) != np.sum(train_labels[:, 1]):  #   Check for imbalance\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(np.argmax(train_labels, axis=1)), y=np.argmax(train_labels, axis=1)\n",
    "    )\n",
    "    class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    print(\"Class Weights:\", class_weights)\n",
    "else:\n",
    "    class_weights = None\n",
    "    print(\"Data is balanced. Not using class weights.\")\n",
    "\n",
    "#   Cell 7: Model Training and Comparison\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "#   1.   Custom CNN\n",
    "print(\"---  Training Custom CNN  ---\")\n",
    "for l2_reg in l2_regs:\n",
    "    for dropout_rate in dropout_rates:\n",
    "        for filters in filter_sizes:\n",
    "            for dense_units in dense_units_sizes:\n",
    "                experiment_name = f\"cnn_l2_{l2_reg}_drop_{dropout_rate}_filters_{filters[0]}_dense_{dense_units}\"\n",
    "                print(f\"Experiment: {experiment_name}\")\n",
    "                cnn_model = create_cnn_model(\n",
    "                    img_height,\n",
    "                    img_width,\n",
    "                    num_classes,\n",
    "                    l2_reg=l2_reg,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    filters=filters,\n",
    "                    dense_units=dense_units,\n",
    "                )\n",
    "                cnn_history = train_model(\n",
    "                    cnn_model,\n",
    "                    train_data,\n",
    "                    train_labels,\n",
    "                    val_data,\n",
    "                    val_labels,\n",
    "                    use_augmentation=use_data_augmentation,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    checkpoint_path=f\"cnn_{experiment_name}.h5\",\n",
    "                    class_weights=class_weights,\n",
    "                    experiment_name=experiment_name\n",
    "                )\n",
    "                cnn_accuracy = evaluate_model(cnn_model, val_data, val_labels, model_name=experiment_name)\n",
    "                model_results[experiment_name] = cnn_accuracy\n",
    "                tf.keras.backend.clear_session()  #   Clear memory\n",
    "\n",
    "#   2.   Transfer Learning Models\n",
    "transfer_learning_models = {\n",
    "    \"VGG16\": VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3)),\n",
    "    \"InceptionV3\": InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3)),\n",
    "    \"Xception\": Xception(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3)),\n",
    "    \"NASNetMobile\": NASNetMobile(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3)),\n",
    "}\n",
    "\n",
    "for model_name, base_model in transfer_learning_models.items():\n",
    "    print(f\"---  Training {model_name}  ---\")\n",
    "    for trainable_layers in [-10, -50]:  #   Try different freezing strategies\n",
    "        experiment_name = f\"{model_name}_trainable_{trainable_layers}\"\n",
    "        print(f\"Experiment: {experiment_name}\")\n",
    "        tl_model = create_transfer_learning_model(\n",
    "            base_model, img_height, img_width, num_classes, trainable_layers=trainable_layers\n",
    "        )\n",
    "        tl_history = train_model(\n",
    "            tl_model,\n",
    "            train_data,\n",
    "            train_labels,\n",
    "            val_data,\n",
    "            val_labels,\n",
    "            use_augmentation=use_data_augmentation,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            checkpoint_path=f\"{experiment_name}.h5\",\n",
    "            class_weights=class_weights,\n",
    "            experiment_name=experiment_name\n",
    "        )\n",
    "        tl_accuracy = evaluate_model(tl_model, val_data, val_labels, model_name=experiment_name)\n",
    "        model_results[experiment_name] = tl_accuracy\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "#   Cell 8: Model Comparison\n",
    "\n",
    "print(\"\\n---  Model Comparison  ---\")\n",
    "sorted_results = sorted(model_results.items(), key=lambda item: item[1], reverse=True)\n",
    "for model_name, accuracy in sorted_results:\n",
    "    print(f\"{model_name}: Validation Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "#   Cell 9: (Optional) Visualize Training History (Example)\n",
    "\n",
    "def plot_history(history, model_name=\"model\"):\n",
    "    \"\"\"Plots training history.\"\"\"\n",
    "    plt.plot(history.history['accuracy'], label=f'{model_name} train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label=f'{model_name} val_accuracy')\n",
    "    plt.plot(history.history['loss'], label=f'{model_name} train_loss')\n",
    "    plt.plot(history.history['val_loss'], label=f'{model_name} val_loss')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Training History: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e08f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
